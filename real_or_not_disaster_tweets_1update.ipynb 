{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "real or not disaster tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpMxexWmcxOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "31bb3d35-2fdb-4bca-871f-a11992daa157"
      },
      "source": [
        "import torch.utils.data\n",
        "import sklearn.metrics\n",
        "import torch\n",
        "import pandas\n",
        "from torch.utils.data import Dataset\n",
        "import tqdm\n",
        "import spacy\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import torchvision \n",
        "from torchvision import models, datasets, transforms\n",
        "SEED = 2222\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "nlp = spacy.load('en')\n",
        "pandas.read_csv('train.csv',header=0).iloc[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                                          1\n",
              "keyword                                                   NaN\n",
              "location                                                  NaN\n",
              "text        Our Deeds are the Reason of this #earthquake M...\n",
              "target                                                      1\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvQZIE7CskCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2852523a-d0af-427a-94d0-22ffa72af795"
      },
      "source": [
        "pandas.read_csv('test.csv',header=0).iloc[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                           0\n",
              "keyword                                    NaN\n",
              "location                                   NaN\n",
              "text        Just happened a terrible car crash\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDr1g4IyfqN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "96073ecd-05bf-46a9-cea1-34801e550865"
      },
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = pandas.read_csv('train.csv',header=0)\n",
        "            \n",
        "            \n",
        "        self.ordinals = {}\n",
        "        for sample in tqdm.tqdm(self.data.text):\n",
        "            for token in nlp (sample.lower(),disable = ['parser','tagger','ner']):\n",
        "                if token.text not in self.ordinals:\n",
        "                    self.ordinals[token.text] = len(self.ordinals)\n",
        "    def __len__ (self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self,idx):\n",
        "        if type(idx) is torch.Tensor:\n",
        "            idx = idx.item()\n",
        "        sample = self.data.iloc[idx]\n",
        "        bag_of_words = torch.zeros(len(self.ordinals))\n",
        "        for token in nlp (sample.text.lower(),disable = ['parser','tagger','ner']):\n",
        "            bag_of_words[self.ordinals[token.text]] += 1\n",
        "        return bag_of_words, torch.tensor(sample.target)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7613/7613 [00:01<00:00, 4020.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1.,  ..., 0., 0., 0.]), tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdno3QpFsuc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0aa2ce02-9cc0-4ee9-c9ad-96e78d9bfacd"
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = pandas.read_csv('test.csv',header=0)\n",
        "            \n",
        "            \n",
        "        self.ordinals = {}\n",
        "        for sample in tqdm.tqdm(self.data.text):\n",
        "            for token in nlp (sample.lower(),disable = ['parser','tagger','ner']):\n",
        "                if token.text not in self.ordinals:\n",
        "                    self.ordinals[token.text] = len(self.ordinals)\n",
        "        #print('efsfgsdfsdf',len(self.ordinals))\n",
        "    def __len__ (self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self,idx):\n",
        "        if type(idx) is torch.Tensor:\n",
        "            idx = idx.item()\n",
        "        sample = self.data.iloc[idx]\n",
        "        bag_of_words = torch.zeros(22610)\n",
        "        for token in nlp (sample.text.lower(),disable = ['parser','tagger','ner']):\n",
        "            bag_of_words[self.ordinals[token.text]] += 1\n",
        "        return bag_of_words"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3263/3263 [00:00<00:00, 4332.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD9FvJXVjNoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Modeltrain (torch.nn.Module):\n",
        "    def __init__(self, input_dimensions,size=128):\n",
        "        super().__init__()\n",
        "        self.layer_one = torch.nn.Linear(input_dimensions, size)\n",
        "        self.activation_one = torch.nn.ReLU()\n",
        "        self.layer_two = torch.nn.Linear(size, size)\n",
        "        self.activation_two = torch.nn.ReLU()\n",
        "        self.shape_outputs = torch.nn.Linear(size, 2)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        buffer = self.layer_one(inputs)\n",
        "        buffer = self.activation_one(buffer)\n",
        "        buffer = self.layer_two(buffer)\n",
        "        buffer = self.activation_two(buffer)\n",
        "        buffer = self.shape_outputs(buffer)\n",
        "        return buffer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT4R3dC5RpzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def valid(model, validationloader):\n",
        "  loss_all = []\n",
        "  with torch.no_grad():\n",
        "      model.eval()\n",
        "      for inputs, actual in validationloader:\n",
        "          results = model(inputs)\n",
        "          loss = loss_function(results, actual)\n",
        "          loss_all.append(loss.item())\n",
        "  return  np.mean(np.array(loss_all))\n",
        "\n",
        "def train(model, trainloader, optimizer, loss_function):\n",
        "  modeltrain.train()\n",
        "  epoch_loss = []\n",
        "  for inputs, outputs in trainloader:\n",
        "        optimizer.zero_grad()\n",
        "        results = modeltrain(inputs)\n",
        "        loss = loss_function(results, outputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss.append(loss.item())\n",
        "  return np.mean(np.array(epoch_loss))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvHh6hMgpOs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "ac899b9f-3ebd-480e-fd40-d4df314aae5c"
      },
      "source": [
        "#training dataset\n",
        "traindataset = TrainDataset()\n",
        "number_for_validating = int(len(traindataset)*0.1)\n",
        "number_for_training = len(traindataset) - number_for_validating\n",
        "validation,train = torch.utils.data.random_split(traindataset,[\n",
        "    number_for_validating,number_for_training])\n",
        "trainloader = torch.utils.data.DataLoader(train,batch_size =16, shuffle =True)\n",
        "validationloader = torch.utils.data.DataLoader(validation,batch_size =16, shuffle =True)\n",
        "print(len(validation),len(train),len(trainloader),len(validationloader))\n",
        "#testing dataset\n",
        "testdataset = TestDataset()\n",
        "test_number = int(len(testdataset))\n",
        "print(test_number)\n",
        "test_loader = torch.utils.data.DataLoader(testdataset,batch_size =16, shuffle =True)\n",
        "#loss\n",
        "modeltrain = Modeltrain(len(traindataset.ordinals))\n",
        "optimizer = torch.optim.Adam(modeltrain.parameters())\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "best_loss = float ('inf')\n",
        "best_epoch = 0\n",
        "for epoch in range(50):\n",
        "    train_loss = train(modeltrain, trainloader, optimizer, loss_function)\n",
        "    valid_loss = valid(modeltrain, validationloader)\n",
        "    if valid_loss<best_loss:\n",
        "        best_loss=valid_loss\n",
        "        best_epoch = epoch\n",
        "        torch.save(modeltrain.state_dict(),'best_model.pt')\n",
        "    print('Epoch:%d, Current_loss:%.4f Best_epoch:%d Best_loss:%.4f'%(epoch,valid_loss,best_epoch, best_loss))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0, Current_loss:4.3099 Best_epoch:0 Best_loss:4.3099\n",
            "Epoch:1, Current_loss:3.5903 Best_epoch:1 Best_loss:3.5903\n",
            "Epoch:2, Current_loss:3.5591 Best_epoch:2 Best_loss:3.5591\n",
            "Epoch:3, Current_loss:3.5129 Best_epoch:3 Best_loss:3.5129\n",
            "Epoch:4, Current_loss:3.4940 Best_epoch:4 Best_loss:3.4940\n",
            "Epoch:5, Current_loss:3.6195 Best_epoch:4 Best_loss:3.4940\n",
            "Epoch:6, Current_loss:3.9763 Best_epoch:4 Best_loss:3.4940\n",
            "Epoch:7, Current_loss:3.6031 Best_epoch:4 Best_loss:3.4940\n",
            "Epoch:8, Current_loss:3.8941 Best_epoch:4 Best_loss:3.4940\n",
            "Epoch:9, Current_loss:3.2738 Best_epoch:9 Best_loss:3.2738\n",
            "Epoch:10, Current_loss:3.4415 Best_epoch:9 Best_loss:3.2738\n",
            "Epoch:11, Current_loss:3.0781 Best_epoch:11 Best_loss:3.0781\n",
            "Epoch:12, Current_loss:3.1829 Best_epoch:11 Best_loss:3.0781\n",
            "Epoch:13, Current_loss:3.2050 Best_epoch:11 Best_loss:3.0781\n",
            "Epoch:14, Current_loss:3.2556 Best_epoch:11 Best_loss:3.0781\n",
            "Epoch:15, Current_loss:3.3457 Best_epoch:11 Best_loss:3.0781\n",
            "Epoch:16, Current_loss:3.3657 Best_epoch:11 Best_loss:3.0781\n",
            "Epoch:17, Current_loss:2.8235 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:18, Current_loss:3.0294 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:19, Current_loss:3.0875 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:20, Current_loss:3.1068 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:21, Current_loss:3.2218 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:22, Current_loss:2.9923 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:23, Current_loss:3.2299 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:24, Current_loss:3.7830 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:25, Current_loss:3.0239 Best_epoch:17 Best_loss:2.8235\n",
            "Epoch:26, Current_loss:2.5647 Best_epoch:26 Best_loss:2.5647\n",
            "Epoch:27, Current_loss:2.5817 Best_epoch:26 Best_loss:2.5647\n",
            "Epoch:28, Current_loss:1.7886 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:29, Current_loss:2.0944 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:30, Current_loss:2.2302 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:31, Current_loss:2.3425 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:32, Current_loss:2.4316 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:33, Current_loss:2.2269 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:34, Current_loss:2.3920 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:35, Current_loss:2.3996 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:36, Current_loss:2.4465 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:37, Current_loss:2.5546 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:38, Current_loss:2.6209 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:39, Current_loss:2.5715 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:40, Current_loss:2.6604 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:41, Current_loss:2.7221 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:42, Current_loss:2.8494 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:43, Current_loss:2.8386 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:44, Current_loss:3.1395 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:45, Current_loss:2.8969 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:46, Current_loss:2.6355 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:47, Current_loss:2.7639 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:48, Current_loss:2.9411 Best_epoch:28 Best_loss:1.7886\n",
            "Epoch:49, Current_loss:3.0907 Best_epoch:28 Best_loss:1.7886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23w2w4yOq460",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0c00162-22e8-44f9-e5f3-049350a9841a"
      },
      "source": [
        "modeltrain.load_state_dict(torch.load('best_model.pt'))\n",
        "results= []\n",
        "with torch.no_grad():\n",
        "    modeltrain.eval()\n",
        "\n",
        "    for inputs in test_loader:\n",
        "        result = modeltrain(inputs).argmax(dim=1).numpy()\n",
        "        results.append(result)\n",
        "results = np.hstack(results)\n",
        "print(results.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3263,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNjVO9DhykoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"foo.csv\", results.astype(int), fmt='%d')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNu1cSXtHGhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}