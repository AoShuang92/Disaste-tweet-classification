{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "real or not disaster tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpMxexWmcxOi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "36b144ee-a04f-46bb-baf0-de2f76dbf9cd"
      },
      "source": [
        "import torch.utils.data\n",
        "import sklearn.metrics\n",
        "import torch\n",
        "import pandas\n",
        "from torch.utils.data import Dataset\n",
        "import tqdm\n",
        "import spacy\n",
        "import numpy as np\n",
        "nlp = spacy.load('en')\n",
        "pandas.read_csv('train.csv',header=0).iloc[0]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                                          1\n",
              "keyword                                                   NaN\n",
              "location                                                  NaN\n",
              "text        Our Deeds are the Reason of this #earthquake M...\n",
              "target                                                      1\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvQZIE7CskCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "2c470e24-5709-4a73-e09a-65b036c1e063"
      },
      "source": [
        "pandas.read_csv('test.csv',header=0).iloc[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                           0\n",
              "keyword                                    NaN\n",
              "location                                   NaN\n",
              "text        Just happened a terrible car crash\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDr1g4IyfqN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a37c60c7-49e5-46b1-a04a-98ca6a0e7818"
      },
      "source": [
        "class TrainDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = pandas.read_csv('train.csv',header=0)\n",
        "            \n",
        "            \n",
        "        self.ordinals = {}\n",
        "        for sample in tqdm.tqdm(self.data.text):\n",
        "            for token in nlp (sample.lower(),disable = ['parser','tagger','ner']):\n",
        "                if token.text not in self.ordinals:\n",
        "                    self.ordinals[token.text] = len(self.ordinals)\n",
        "    def __len__ (self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self,idx):\n",
        "        if type(idx) is torch.Tensor:\n",
        "            idx = idx.item()\n",
        "        sample = self.data.iloc[idx]\n",
        "        bag_of_words = torch.zeros(len(self.ordinals))\n",
        "        for token in nlp (sample.text.lower(),disable = ['parser','tagger','ner']):\n",
        "            bag_of_words[self.ordinals[token.text]] += 1\n",
        "        return bag_of_words, torch.tensor(sample.target)\n",
        "traindataset = TrainDataset()\n",
        "traindataset[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7613/7613 [00:01<00:00, 4181.32it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1.,  ..., 0., 0., 0.]), tensor(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdno3QpFsuc0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "cedc447d-180c-46e3-8415-81b0f97cfc22"
      },
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        self.data = pandas.read_csv('test.csv',header=0)\n",
        "            \n",
        "            \n",
        "        self.ordinals = {}\n",
        "        for sample in tqdm.tqdm(self.data.text):\n",
        "            for token in nlp (sample.lower(),disable = ['parser','tagger','ner']):\n",
        "                if token.text not in self.ordinals:\n",
        "                    self.ordinals[token.text] = len(self.ordinals)\n",
        "        #print('efsfgsdfsdf',len(self.ordinals))\n",
        "    def __len__ (self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self,idx):\n",
        "        if type(idx) is torch.Tensor:\n",
        "            idx = idx.item()\n",
        "        sample = self.data.iloc[idx]\n",
        "        bag_of_words = torch.zeros(22610)\n",
        "        for token in nlp (sample.text.lower(),disable = ['parser','tagger','ner']):\n",
        "            bag_of_words[self.ordinals[token.text]] += 1\n",
        "        return bag_of_words\n",
        "testdataset = TestDataset()\n",
        "testdataset[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3263/3263 [00:00<00:00, 4456.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.,  ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJpni-NQgylR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bd21ad6-829e-4a32-bd1b-57299b8f0f75"
      },
      "source": [
        "len(traindataset.ordinals)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22610"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKq5R5iotRlC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0353b803-e05f-469f-ca45-a35ea7f17922"
      },
      "source": [
        "len(testdataset.ordinals)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12711"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXig_m-2jHXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cff3821-5d7f-4529-9cbd-60c9a497a7be"
      },
      "source": [
        "number_for_validating = int(len(traindataset)*0.1)\n",
        "number_for_training = len(traindataset) - number_for_validating\n",
        "validation,train = torch.utils.data.random_split(traindataset,[\n",
        "    number_for_validating,number_for_training])\n",
        "trainloader = torch.utils.data.DataLoader(train,batch_size =16, shuffle =True)\n",
        "validationloader = torch.utils.data.DataLoader(validation,batch_size =16, shuffle =True)\n",
        "print(len(validation),len(train),len(trainloader),len(validationloader))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "761 6852 429 48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAB6-bnIuuQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "702e4b1c-4422-4d6b-9c23-c4d7982dfd36"
      },
      "source": [
        "test_number = int(len(testdataset))\n",
        "print(test_number)\n",
        "test_loader = torch.utils.data.DataLoader(testdataset,batch_size =16, shuffle =True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD9FvJXVjNoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Modeltrain (torch.nn.Module):\n",
        "    def __init__(self, input_dimensions,size=128):\n",
        "        super().__init__()\n",
        "        self.layer_one = torch.nn.Linear(input_dimensions, size)\n",
        "        self.activation_one = torch.nn.ReLU()\n",
        "        self.layer_two = torch.nn.Linear(size, size)\n",
        "        self.activation_two = torch.nn.ReLU()\n",
        "        self.shape_outputs = torch.nn.Linear(size, 2)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        buffer = self.layer_one(inputs)\n",
        "        buffer = self.activation_one(buffer)\n",
        "        buffer = self.layer_two(buffer)\n",
        "        buffer = self.activation_two(buffer)\n",
        "        buffer = self.shape_outputs(buffer)\n",
        "        return buffer\n",
        "modeltrain = Modeltrain(len(traindataset.ordinals))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvHh6hMgpOs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "f955127d-6d2a-4d8c-bdbf-358ea70d0eeb"
      },
      "source": [
        "optimizer = torch.optim.Adam(modeltrain.parameters())\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "modeltrain.train()\n",
        "for epoch in range(16):\n",
        "    losses = []\n",
        "    for inputs, outputs in tqdm.tqdm(trainloader):\n",
        "        optimizer.zero_grad()\n",
        "        results = modeltrain(inputs)\n",
        "        loss = loss_function(results, outputs)\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"Loss: {0}\".format(torch.tensor(losses).mean()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:25<00:00, 16.83it/s]\n",
            "  0%|          | 2/429 [00:00<00:25, 16.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.5005127787590027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:25<00:00, 16.97it/s]\n",
            "  0%|          | 2/429 [00:00<00:29, 14.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.2223334163427353\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:32<00:00, 13.31it/s]\n",
            "  0%|          | 2/429 [00:00<00:31, 13.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.09026764333248138\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:33<00:00, 12.70it/s]\n",
            "  0%|          | 2/429 [00:00<00:32, 13.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.0559755340218544\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.60it/s]\n",
            "  0%|          | 2/429 [00:00<00:34, 12.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.038428500294685364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:33<00:00, 12.66it/s]\n",
            "  0%|          | 2/429 [00:00<00:34, 12.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.031145405024290085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.61it/s]\n",
            "  0%|          | 2/429 [00:00<00:32, 13.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.024234289303421974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:36<00:00, 11.74it/s]\n",
            "  0%|          | 2/429 [00:00<00:32, 13.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.01919711008667946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.47it/s]\n",
            "  0%|          | 2/429 [00:00<00:32, 13.23it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.018085716292262077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.45it/s]\n",
            "  0%|          | 2/429 [00:00<00:32, 13.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.01608758606016636\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.43it/s]\n",
            "  0%|          | 2/429 [00:00<00:34, 12.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.014921056106686592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.40it/s]\n",
            "  0%|          | 2/429 [00:00<00:32, 13.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.012805137783288956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.36it/s]\n",
            "  0%|          | 2/429 [00:00<00:32, 13.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.013003408908843994\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.38it/s]\n",
            "  0%|          | 2/429 [00:00<00:33, 12.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.01235273852944374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.38it/s]\n",
            "  0%|          | 2/429 [00:00<00:32, 13.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.012400202453136444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 429/429 [00:34<00:00, 12.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.012907399795949459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm_eeYFApaJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "62334547-5876-41f6-a788-f0440e54140d"
      },
      "source": [
        "results_buffer = []\n",
        "actual_buffer = []\n",
        "with torch.no_grad():\n",
        "    modeltrain.eval()\n",
        "\n",
        "    for inputs, actual in validationloader:\n",
        "        results = modeltrain(inputs).argmax(dim=1).numpy()\n",
        "        results_buffer.append(results)\n",
        "        actual_buffer.append(actual)\n",
        "print(sklearn.metrics.classification_report(\n",
        "    np.concatenate(actual_buffer),\n",
        "    np.concatenate(results_buffer)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.79       444\n",
            "           1       0.72      0.66      0.69       317\n",
            "\n",
            "    accuracy                           0.75       761\n",
            "   macro avg       0.74      0.74      0.74       761\n",
            "weighted avg       0.75      0.75      0.75       761\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23w2w4yOq460",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddbaa2b4-d53b-4529-9dd8-33a081774ae5"
      },
      "source": [
        "results= []\n",
        "with torch.no_grad():\n",
        "    modeltrain.eval()\n",
        "\n",
        "    for inputs in test_loader:\n",
        "        result = modeltrain(inputs).argmax(dim=1).numpy()\n",
        "        results.append(result)\n",
        "results = np.hstack(results)\n",
        "print(results.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3263,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNjVO9DhykoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"foo.csv\", results.astype(int), fmt='%d')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNu1cSXtHGhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}