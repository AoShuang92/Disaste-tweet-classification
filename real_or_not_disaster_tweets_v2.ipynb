{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "kpMxexWmcxOi",
    "outputId": "6ac70514-f8eb-4f78-809e-03c0760a712f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                          1\n",
       "keyword                                                   NaN\n",
       "location                                                  NaN\n",
       "text        Our Deeds are the Reason of this #earthquake M...\n",
       "target                                                      1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.utils.data\n",
    "import sklearn.metrics\n",
    "import torch\n",
    "import pandas\n",
    "from torch.utils.data import Dataset\n",
    "import tqdm\n",
    "import spacy\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import torchvision \n",
    "from torchvision import models, datasets, transforms\n",
    "SEED = 2222\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "nlp = spacy.load('en')\n",
    "pandas.read_csv('train.csv',header=0).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "SvQZIE7CskCm",
    "outputId": "2852523a-d0af-427a-94d0-22ffa72af795"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                           0\n",
       "keyword                                    NaN\n",
       "location                                   NaN\n",
       "text        Just happened a terrible car crash\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.read_csv('test.csv',header=0).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "cDr1g4IyfqN2",
    "outputId": "96073ecd-05bf-46a9-cea1-34801e550865"
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = pandas.read_csv('train.csv',header=0)\n",
    "            \n",
    "            \n",
    "        self.ordinals = {}\n",
    "        for sample in tqdm.tqdm(self.data.text):\n",
    "            for token in nlp (sample.lower(),disable = ['parser','tagger','ner']):\n",
    "                if token.text not in self.ordinals:\n",
    "                    self.ordinals[token.text] = len(self.ordinals)\n",
    "    def __len__ (self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        if type(idx) is torch.Tensor:\n",
    "            idx = idx.item()\n",
    "        sample = self.data.iloc[idx]\n",
    "        bag_of_words = torch.zeros(len(self.ordinals))\n",
    "        for token in nlp (sample.text.lower(),disable = ['parser','tagger','ner']):\n",
    "            bag_of_words[self.ordinals[token.text]] += 1\n",
    "        return bag_of_words, torch.tensor(sample.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jdno3QpFsuc0",
    "outputId": "0aa2ce02-9cc0-4ee9-c9ad-96e78d9bfacd"
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = pandas.read_csv('test.csv',header=0)\n",
    "            \n",
    "            \n",
    "        self.ordinals = {}\n",
    "        for sample in tqdm.tqdm(self.data.text):\n",
    "            for token in nlp (sample.lower(),disable = ['parser','tagger','ner']):\n",
    "                if token.text not in self.ordinals:\n",
    "                    self.ordinals[token.text] = len(self.ordinals)\n",
    "        #print('efsfgsdfsdf',len(self.ordinals))\n",
    "    def __len__ (self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self,idx):\n",
    "        if type(idx) is torch.Tensor:\n",
    "            idx = idx.item()\n",
    "        sample = self.data.iloc[idx]\n",
    "        bag_of_words = torch.zeros(22610)\n",
    "        for token in nlp (sample.text.lower(),disable = ['parser','tagger','ner']):\n",
    "            bag_of_words[self.ordinals[token.text]] += 1\n",
    "        return bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GD9FvJXVjNoc"
   },
   "outputs": [],
   "source": [
    "class Modeltrain (torch.nn.Module):\n",
    "    def __init__(self, input_dimensions,size=128):\n",
    "        super().__init__()\n",
    "        self.layer_one = torch.nn.Linear(input_dimensions, size)\n",
    "        self.activation_one = torch.nn.ReLU()\n",
    "        self.layer_two = torch.nn.Linear(size, size)\n",
    "        self.activation_two = torch.nn.ReLU()\n",
    "        self.shape_outputs = torch.nn.Linear(size, 2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        buffer = self.layer_one(inputs)\n",
    "        buffer = self.activation_one(buffer)\n",
    "        buffer = self.layer_two(buffer)\n",
    "        buffer = self.activation_two(buffer)\n",
    "        buffer = self.shape_outputs(buffer)\n",
    "        return buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cT4R3dC5RpzV"
   },
   "outputs": [],
   "source": [
    "\n",
    "def valid(model, validationloader):\n",
    "  loss_all = []\n",
    "  with torch.no_grad():\n",
    "      model.eval()\n",
    "      for inputs, actual in validationloader:\n",
    "          results = model(inputs)\n",
    "          loss = loss_function(results, actual)\n",
    "          loss_all.append(loss.item())\n",
    "  return  np.mean(np.array(loss_all))\n",
    "\n",
    "def train(model, trainloader, optimizer, loss_function):\n",
    "  model.train()\n",
    "  epoch_loss = []\n",
    "  for inputs, outputs in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        results = model(inputs)\n",
    "        loss = loss_function(results, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "  return np.mean(np.array(epoch_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 885
    },
    "colab_type": "code",
    "id": "qvHh6hMgpOs_",
    "outputId": "ac899b9f-3ebd-480e-fd40-d4df314aae5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7613/7613 [00:02<00:00, 2712.52it/s]\n",
      " 11%|█         | 347/3263 [00:00<00:00, 3464.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761 6852 429 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3263/3263 [00:01<00:00, 2642.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3263\n"
     ]
    }
   ],
   "source": [
    "#training dataset\n",
    "traindataset = TrainDataset()\n",
    "number_for_validating = int(len(traindataset)*0.1)\n",
    "number_for_training = len(traindataset) - number_for_validating\n",
    "valid_dataset, train_dataset = torch.utils.data.random_split(traindataset,[\n",
    "    number_for_validating,number_for_training])\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size =16, shuffle =True)\n",
    "validationloader = torch.utils.data.DataLoader(valid_dataset, batch_size =16, shuffle =True)\n",
    "print(len(valid_dataset),len(train_dataset),len(trainloader),len(validationloader))\n",
    "#testing dataset\n",
    "testdataset = TestDataset()\n",
    "test_number = int(len(testdataset))\n",
    "print(test_number)\n",
    "test_loader = torch.utils.data.DataLoader(testdataset,batch_size =16, shuffle =True)\n",
    "#loss\n",
    "model = Modeltrain(len(traindataset.ordinals))\n",
    "optimizer = torch.optim.Adam(modeltrain.parameters())\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "best_loss = float ('inf')\n",
    "best_epoch = 0\n",
    "for epoch in range(50):\n",
    "    train_loss = train(model, trainloader, optimizer, loss_function)\n",
    "    valid_loss = valid(model, validationloader)\n",
    "    if valid_loss<best_loss:\n",
    "        best_loss=valid_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(modeltrain.state_dict(),'best_model.pt')\n",
    "    print('Epoch:%d, Current_loss:%.4f Best_epoch:%d Best_loss:%.4f'%(epoch,valid_loss,best_epoch, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "23w2w4yOq460",
    "outputId": "e0c00162-22e8-44f9-e5f3-049350a9841a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3263,)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "results= []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    for inputs in test_loader:\n",
    "        result = modeltrain(inputs).argmax(dim=1).numpy()\n",
    "        results.append(result)\n",
    "results = np.hstack(results)\n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QNjVO9DhykoJ"
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"foo.csv\", results.astype(int), fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "real or not disaster tweets_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
